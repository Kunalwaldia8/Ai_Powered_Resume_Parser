# AI-Powered Resume Parser and Ranking System

An intelligent web application that leverages Natural Language Processing (NLP) and machine learning techniques to analyze, parse, and rank resumes against job descriptions. Built with a React frontend and Flask backend, this system provides an intuitive interface for automated resume screening and candidate ranking.

![Resume Parser Banner](./frontend/public/banner.png)

## ğŸŒŸ Key Features

### ğŸ“„ Document Processing

- Support for multiple file formats (PDF, DOCX)
- Smart text extraction and section identification
- Automatic contact information extraction
- Bulk resume processing capabilities

### ğŸ¤– AI-Powered Analysis

- Intelligent skill extraction and categorization
- Context-aware skill matching
- Natural language understanding
- Semantic similarity analysis
- Machine learning based ranking algorithm

### ğŸ¯ Advanced Ranking

- Customizable skill categorization (Required/Essential/Good to Have)
- Weighted scoring system
- Comprehensive candidate evaluation
- Detailed skill gap analysis

### ğŸ’« Modern User Interface

- Intuitive drag-and-drop file upload
- Interactive skill categorization
- Real-time processing feedback
- Beautiful responsive design
- Light/Dark theme support
- Downloadable detailed reports

## ğŸš€ Tech Stack

### Frontend

- React 18
- Vite
- TailwindCSS
- Context API
- Axios

### Backend

- Python 3.8+
- Flask
- spaCy
- NLTK
- PyPDF2
- python-docx

## ğŸ› ï¸ Installation

### Prerequisites

- Node.js 14+
- Python 3.8+
- pip
- npm or yarn

### Backend Setup

1. Navigate to backend directory:

```bash
cd backend
```

2. Create and activate virtual environment:

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate   # Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Download NLTK data:

```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('averaged_perceptron_tagger'); nltk.download('stopwords')"
```

### Frontend Setup

1. Navigate to frontend directory:

```bash
cd frontend
```

2. Install dependencies:

```bash
npm install
# or
yarn install
```

### Environment Setup

1. Backend (.env):

```env
FLASK_ENV=development
UPLOAD_FOLDER=static/uploads
MAX_CONTENT_LENGTH=16777216
```

2. Frontend (.env):

```env
VITE_API_URL=http://localhost:5000
```

## ğŸš€ Running the Application

1. Start the backend server:

```bash
cd backend
python app.py
```

2. Start the frontend development server:

```bash
cd frontend
npm run dev
```

3. Access the application at: `http://localhost:5173`

## ğŸ“‚ Project Structure

```
resume_ranking_system/
â”œâ”€â”€ frontend/                 # React frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ pages/          # Page components
â”‚   â”‚   â”œâ”€â”€ context/        # React contexts
â”‚   â”‚   â””â”€â”€ utils/          # Utility functions
â”‚   â””â”€â”€ public/             # Static assets
â”‚
â”œâ”€â”€ backend/                 # Flask backend application
â”‚   â”œâ”€â”€ app.py              # Main Flask application
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â”œâ”€â”€ skill_extractor.py
â”‚   â”‚   â”œâ”€â”€ resume_ranker.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ uploads/        # File upload directory
â”‚   â””â”€â”€ templates/          # Report templates
```

## ğŸ”„ How It Works

1. **Document Upload & Processing**

   - User uploads resumes and job description
   - System extracts text and identifies sections
   - Contact information is automatically parsed

2. **Skill Analysis**

   - AI identifies technical skills and competencies
   - Skills are matched against known patterns
   - Context and relevance are considered

3. **Interactive Categorization**

   - User categorizes job requirements
   - Skills are weighted based on importance
   - System adapts ranking algorithm accordingly

4. **Ranking & Results**
   - Candidates are scored based on matches
   - Detailed analysis is generated
   - Results are presented in intuitive UI

## ğŸ”’ Security Features

- Secure file handling
- Input validation
- Session-based processing
- File size limits
- Directory traversal prevention

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“„ License

MIT License - See [LICENSE](./LICENSE) for details

## ğŸ‘¥ Team

- [Akshat Bisht] - ML/NLP Implementation
- [Kunal Waldia] - Backend Development
- [Divyansh Dhaundiyal] - Frontend Development & UI/UX
